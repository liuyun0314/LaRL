defaults:
  - _self_
  - env: JSP
  - override hydra/launcher: local
  - override hydra/output: local

hydra:
  job:
    chdir: True

env:
  task: JSP
  env_name: workshop
  description: to process multiple job shop scheduling tasks simultaneously to optimize all objectives under dynamic environments. Generally, each job shop scheduling task tends to search for a scheduling solution to optimize a specific objection function. Each task, consisting of multiple jobs with a sequence of operations, need to be processed by a set of machines. There are three job shop scheduling tasks, each of which has distinct objectives, i.e., mean-weighted-tardiness, mean-weighted-flowtime, and max-weighted-tardiness


# LLM parameters

# use deepseek-chat for Eureqa
#model: deepseek-chat  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
#api_key: 'sk-8a7c8b1000df4b7dbcc40c2a2bf9b590'  # Eureqa API key (required for Eureka)  deepseek
#base_url: "https://api.deepseek.com"

# use qianwen for Eureqa
model: qwen-max-latest    # qwen-max-latest  # qwen-max    #qwen-plus   # qwen-vl-plus-0125    # qwen-plus, qwen-vl-plus-0125, qwen2.5-vl-72b-instruct  qwen-plus-2025-04-28
api_key: 'sk-c08912e780b543ca95c3c0676d2a3b2f'  # Eureqa API key (required for Eureka)   千问
base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
temperature: 1.0
check_temperature: 0.3
suffix: LLM  # suffix for generated files (indicates LLM model)
#model: gpt-4-0314  # LLM model (other options are gpt-4, gpt-4-0613, gpt-3.5-turbo-16k-0613)
#temperature: 1.0
#suffix: GPT  # suffix for generated files (indicates LLM model)

# Eureka parameters
iteration: 2 # how many iterations of running
sample: 1 # 3 number of samples to generate per iteration
max_iterations: 3 #  3000 RL Policy training iterations (decrease this to make the feedback loop faster)
num_eval: 5 # number of evaluation episodes to run for the final reward
capture_video: False # whether to capture policy rollout videos

# Weights and Biases
use_wandb: False # whether to use wandb for logging
wandb_username: "" # wandb username if logging with wandb
wandb_project: "" # wandb project if logging with wandb